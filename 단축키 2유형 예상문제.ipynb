{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e137830b-75ee-4886-b5a2-be6dc74126d6",
   "metadata": {},
   "source": [
    "- 01 고객 3,500명에 대한 학습용 데이터(x_train.csv,y_train.csv)를 이용하여 성별예측모형을 만든 후,\n",
    "- 이를 평가용 데이터(x_test.csv)에 적용하여 얻은 2482명의 고객 성별 예측값(남자일 확률)을 아래 형식의 csv파일로 제출하시오.\n",
    "- (제출할 모델의 성능은 ROC_AUC 평가지표에 따라 채점)\n",
    "- 제출형태\n",
    "- 변수명.to_csv('수험번호.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c47351db-240b-4a79-af48-c713ea0a1e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6214285714285714\n",
      "0.5650825277775361\n",
      "[[346  91]\n",
      " [174  89]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x_train = pd.read_csv('data/x_train.csv', encoding='cp949')\n",
    "x_test = pd.read_csv('data/x_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('data/y_train.csv', encoding='cp949')\n",
    "\n",
    "# 1. 라이브러리 및 데이터 확인\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# print(y_train.info()) # 환불금액 결측치\n",
    "# object type\n",
    "cust_id = x_test['cust_id'].copy()\n",
    "x_train = x_train.drop(columns=['cust_id'])\n",
    "x_test = x_test.drop(columns=['cust_id'])\n",
    "y_train = y_train.drop(['cust_id'], axis=1)\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# print(y_train.info())\n",
    "# 2. 데이터 탐색(EDA)\n",
    "# print(x_train.describe().T)\n",
    "# print(x_test.describe().T)\n",
    "# print(x_train.describe(include='object').T)\n",
    "# print(x_test.describe(include='object').T)\n",
    "# print(y_train.value_counts())\n",
    "# 3. 데이터 전처리 및 분리\n",
    "# 1)결측치 2)이상치 3)변수 처리\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isnull().sum())\n",
    "# print(y_train.isnull().sum())\n",
    "med = x_train['환불금액'].median()\n",
    "x_train['환불금액'] = x_train['환불금액'].fillna(med)\n",
    "x_test['환불금액'] = x_test['환불금액'].fillna(med)\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isnull().sum())\n",
    "# print(y_train.isnull().sum())\n",
    "x_train = pd.get_dummies(x_train, dtype='uint8')\n",
    "x_test = pd.get_dummies(x_test, dtype='uint8')\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "x_test = x_test.reindex(columns=x_train.columns, fill_value=0)\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(x_train.head(3))\n",
    "# print(x_test.head(3))\n",
    "# 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                  y_train['gender'],\n",
    "                                                  test_size=0.2,\n",
    "                                                  stratify=y_train['gender']\n",
    "                                                  )\n",
    "# print(x_train.shape)\n",
    "# print(x_val.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)\n",
    "\n",
    "# 4. 모델링 및 성능평가\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_val)\n",
    "#print(y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(acc)\n",
    "print(auc)\n",
    "print(cm)\n",
    "\n",
    "# y_result = model.predict(x_test)\n",
    "# y_result_prob = model.predict_proba(x_test)\n",
    "# # print(y_result[:5])\n",
    "# # print(y_result_prob[:5])\n",
    "# result = pd.DataFrame({'result':y_result,\n",
    "#                        'prob0':y_result_prob[:,0],\n",
    "#                        'prob1':y_result_prob[:,1]})\n",
    "# # print(result[:5])\n",
    "\n",
    "# # 5. 예측값 제출\n",
    "# pd.DataFrame({'cust_id':cust_id, 'gender':y_result_prob[:,0]}).to_csv('단축키2유형1.csv', index=False)\n",
    "# df = pd.read_csv('단축키2유형1.csv')\n",
    "# print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "058d3ed4-7902-413e-93a0-1dcd8db8d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45 0.55]\n",
      " [0.82 0.18]\n",
      " [0.87 0.13]\n",
      " ...\n",
      " [0.45 0.55]\n",
      " [0.61 0.39]\n",
      " [0.49 0.51]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "import pandas as pd\n",
    "x_train = pd.read_csv('data/x_train.csv', encoding='cp949')\n",
    "x_test = pd.read_csv('data/x_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('data/y_train.csv', encoding='cp949')\n",
    "# print(x_train.head(3))\n",
    "# print(x_test.head(3))\n",
    "# print(y_train.head(3))\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# print(y_train.info())\n",
    "cust_id = x_test.copy()\n",
    "x_train = x_train.drop(['cust_id'], axis=1)\n",
    "y_train = y_train.drop(columns=['cust_id'])\n",
    "x_test = x_test.drop(columns=['cust_id'])\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isna().sum())\n",
    "\n",
    "# 환불금액이 결측치라는 건 환불금액이 없다는 말로 파악\n",
    "x_train['환불금액'] = x_train['환불금액'].fillna(0)\n",
    "x_test['환불금액'] = x_test['환불금액'].fillna(0)\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isna().sum())\n",
    "\n",
    "# 인코딩 변환\n",
    "# print(x_train['주구매상품'].unique())\n",
    "# print(x_test['주구매상품'].unique())\n",
    "# print(x_train['주구매상품'].unique().size)\n",
    "# print(x_test['주구매상품'].unique().size)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_상품 = LabelEncoder()\n",
    "encoder_지점 = LabelEncoder()\n",
    "x_train['주구매상품'] = encoder_상품.fit_transform(x_train['주구매상품'])\n",
    "x_train['주구매지점'] = encoder_지점.fit_transform(x_train['주구매지점'])\n",
    "#print(x_train.head(3))\n",
    "def safe_transform(encoder, labels):\n",
    "    unseen_label = -1\n",
    "    label_mapping = {label:idx for idx,label in enumerate(encoder.classes_)}\n",
    "    return np.array([label_mapping.get(label, unseen_label) for label in labels])\n",
    "\n",
    "x_test['주구매상품'] = safe_transform(encoder_상품, x_test['주구매상품'])\n",
    "x_test['주구매지점'] = safe_transform(encoder_지점, x_test['주구매지점'])\n",
    "#print(x_test.head(3))\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# 표준화를 할 필요가 있나?\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "# print(x_train.head(3))\n",
    "# print(x_train.describe().T)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
    "# print(x_test.head(3))\n",
    "# print(x_test.describe().T)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "#                                                   y_train['gender'],\n",
    "#                                                   test_size=0.2,\n",
    "#                                                   stratify=y_train['gender'],\n",
    "#                                                   random_state=24\n",
    "#                                                   )\n",
    "# # print(x_train.shape)\n",
    "# # print(x_val.shape)\n",
    "# # print(y_train.shape)\n",
    "# # print(y_val.shape)\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(x_train, y_train)\n",
    "# y_pred = model.predict(x_val)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# acc = accuracy_score(y_val, y_pred)\n",
    "# auc = roc_auc_score(y_val, y_pred)\n",
    "# # print(acc)\n",
    "# # print(auc)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train['gender'])\n",
    "y_pred = model.predict(x_train)\n",
    "#print(y_result)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "acc2 = accuracy_score(y_train['gender'], y_pred)\n",
    "auc2 = roc_auc_score(y_train.values.ravel(), y_pred)\n",
    "# print(acc2)\n",
    "# print(auc2)\n",
    "\n",
    "y_result = model.predict(x_test)\n",
    "#print(y_result)\n",
    "y_result_prob = model.predict_proba(x_test)\n",
    "print(y_result_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "417aa1e8-0914-4a49-a15a-a94f56199c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "import pandas as pd\n",
    "x_train = pd.read_csv('data/x_train.csv', encoding='cp949')\n",
    "x_test = pd.read_csv('data/x_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('data/y_train.csv', encoding='cp949')\n",
    "# print(x_train.head(3))\n",
    "# print(x_test.head(3))\n",
    "# print(y_train.head(3))\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# print(y_train.info())\n",
    "cust_id = x_test.copy()\n",
    "x_train = x_train.drop(['cust_id'], axis=1)\n",
    "y_train = y_train.drop(columns=['cust_id'])\n",
    "x_test = x_test.drop(columns=['cust_id'])\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isna().sum())\n",
    "\n",
    "# 환불금액이 결측치라는 건 환불금액이 없다는 말로 파악\n",
    "x_train['환불금액'] = x_train['환불금액'].fillna(0)\n",
    "x_test['환불금액'] = x_test['환불금액'].fillna(0)\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isna().sum())\n",
    "\n",
    "# 인코딩 변환\n",
    "# print(x_train['주구매상품'].unique())\n",
    "# print(x_test['주구매상품'].unique())\n",
    "# print(x_train['주구매상품'].unique().size)\n",
    "# print(x_test['주구매상품'].unique().size)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_상품 = LabelEncoder()\n",
    "encoder_지점 = LabelEncoder()\n",
    "x_train['주구매상품'] = encoder_상품.fit_transform(x_train['주구매상품'])\n",
    "x_train['주구매지점'] = encoder_지점.fit_transform(x_train['주구매지점'])\n",
    "#print(x_train.head(3))\n",
    "def safe_transform(encoder, labels):\n",
    "    unseen_label = -1\n",
    "    label_mapping = {label:idx for idx,label in enumerate(encoder.classes_)}\n",
    "    return np.array([label_mapping.get(label, unseen_label) for label in labels])\n",
    "\n",
    "x_test['주구매상품'] = safe_transform(encoder_상품, x_test['주구매상품'])\n",
    "x_test['주구매지점'] = safe_transform(encoder_지점, x_test['주구매지점'])\n",
    "#print(x_test.head(3))\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# 표준화를 할 필요가 있나?\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "# print(x_train.head(3))\n",
    "# print(x_train.describe().T)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
    "# print(x_test.head(3))\n",
    "# print(x_test.describe().T)\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'max_depth':[3,4,5,6],\n",
    "          'min_samples_leaf':[3,4,5,6],\n",
    "          'min_samples_split':[2,4,6]}\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "grid_cv = GridSearchCV(rf, param_grid=params, cv=2)\n",
    "grid_cv.fit(x_train, y_train['gender'])\n",
    "\n",
    "# print(\"최적 하이퍼파라미터 : \", grid_cv.best_params_)\n",
    "# print(\"최적 score : \", grid_cv.best_score_)\n",
    "\n",
    "model_cv = RandomForestClassifier(n_estimators=50, \n",
    "                                  max_depth=5, \n",
    "                                  min_samples_leaf=4,\n",
    "                                  min_samples_split=2,\n",
    "                                  random_state=0)\n",
    "model_cv.fit(x_train, y_train['gender'])\n",
    "y_result = model_cv.predict(x_test)\n",
    "print(y_result[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "70826f56-93f0-4b91-9e16-cf50677ac696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1]\n",
      "0.6257142857142857\n",
      "0.585925468324473\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "import pandas as pd\n",
    "x_train = pd.read_csv('data/x_train.csv', encoding='cp949')\n",
    "x_test = pd.read_csv('data/x_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('data/y_train.csv', encoding='cp949')\n",
    "# print(x_train.head(3))\n",
    "# print(x_test.head(3))\n",
    "# print(y_train.head(3))\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# print(y_train.info())\n",
    "cust_id = x_test.copy()\n",
    "x_train = x_train.drop(['cust_id'], axis=1)\n",
    "y_train = y_train.drop(columns=['cust_id'])\n",
    "x_test = x_test.drop(columns=['cust_id'])\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isna().sum())\n",
    "\n",
    "# 환불금액이 결측치라는 건 환불금액이 없다는 말로 파악\n",
    "x_train['환불금액'] = x_train['환불금액'].fillna(0)\n",
    "x_test['환불금액'] = x_test['환불금액'].fillna(0)\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isna().sum())\n",
    "\n",
    "# 인코딩 변환\n",
    "# print(x_train['주구매상품'].unique())\n",
    "# print(x_test['주구매상품'].unique())\n",
    "# print(x_train['주구매상품'].unique().size)\n",
    "# print(x_test['주구매상품'].unique().size)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder_상품 = LabelEncoder()\n",
    "encoder_지점 = LabelEncoder()\n",
    "x_train['주구매상품'] = encoder_상품.fit_transform(x_train['주구매상품'])\n",
    "x_train['주구매지점'] = encoder_지점.fit_transform(x_train['주구매지점'])\n",
    "#print(x_train.head(3))\n",
    "def safe_transform(encoder, labels):\n",
    "    unseen_label = -1\n",
    "    label_mapping = {label:idx for idx,label in enumerate(encoder.classes_)}\n",
    "    return np.array([label_mapping.get(label, unseen_label) for label in labels])\n",
    "\n",
    "x_test['주구매상품'] = safe_transform(encoder_상품, x_test['주구매상품'])\n",
    "x_test['주구매지점'] = safe_transform(encoder_지점, x_test['주구매지점'])\n",
    "#print(x_test.head(3))\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# 표준화를 할 필요가 있나?\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "# print(x_train.head(3))\n",
    "# print(x_train.describe().T)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
    "# print(x_test.head(3))\n",
    "# print(x_test.describe().T)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                  y_train['gender'],\n",
    "                                                  test_size=0.2,\n",
    "                                                  stratify=y_train['gender'],\n",
    "                                                  random_state=24\n",
    "                                                  )\n",
    "# print(x_train.shape)\n",
    "# print(x_val.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_val)\n",
    "y_pred_prob = knn.predict_proba(x_val)\n",
    "print(y_pred[:5])\n",
    "# print(y_result_prob[:5])\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(acc)\n",
    "print(auc)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0788cb-2196-4a07-8237-72d8a9ed37f4",
   "metadata": {},
   "source": [
    "- 02 보험관련 학습용 데이터 Insurance_train_10.csv 데이터를 이용하여 \"Segmentation\"예측모형을 개발하려고 한다.\n",
    "- 자동차 회사는 기존 시장에서 영업팀은 모든 고객을 4개의 \"Segmentation\"으로 분류하고 새로운 시장에서 동일한 전략을 사용할 계획이다.\n",
    "- 채점은 제출된 CSV 파일의 macro-F1 평가지표에 따라 구간별로 배정 과적합 등의 사유로 평가용 데이터의 평가지표와 채점용 데이터의 평가지표는 다를 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e669853e-3e1e-4e5d-8e00-fa85c78fc6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 3 ... 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "train = pd.read_csv('data/Insurance_train_10.csv')\n",
    "test = pd.read_csv('data/Insurance_test_10.csv')\n",
    "x_train = train.copy()\n",
    "x_test = test.copy()\n",
    "\n",
    "# 1. 라이브러리 및 데이터 확인\n",
    "# print(x_train.head(3))\n",
    "# print(x_test.head(3))\n",
    "# print(y_train.head(3))\n",
    "# print(x_train.info())\n",
    "# print(x_test.info())\n",
    "# print(y_train.info()) # 결측치 ever_married, graduated, profession\n",
    "\n",
    "# 2. 데이터 탐색(EDA)\n",
    "# print(x_train.describe().T)\n",
    "# print(x_test.describe().T)\n",
    "# print(x_train.info()) # dtype object\n",
    "# print(x_train.describe(include='object').T)\n",
    "# print(x_test.describe(include='object').T) # ever_married 4056개 (Yes) / graduated 4370개 (Yes) \n",
    "#                                            # / profession 2247개 (Artist)\n",
    "#print(y_train.value_counts())\n",
    "#print(x_train['Profession'].value_counts())\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isnull().sum())\n",
    "# print(y_train.isnull().sum())\n",
    "\n",
    "# 3. 데이터 전처리 및 분리\n",
    "x_train = x_train.dropna()\n",
    "x_test = x_test.dropna()\n",
    "y_train = x_train['Segmentation']\n",
    "x_train = x_train.drop(['Segmentation'], axis=1)\n",
    "# print(x_train.isnull().sum())\n",
    "# print(x_test.isnull().sum())\n",
    "# print(x_train['Gender'].unique())\n",
    "# print(x_train['Ever_Married'].unique())\n",
    "# print(x_train['Graduated'].unique())\n",
    "# print(x_train['Profession'].unique())\n",
    "#print(x_train['Spending_Score'].unique())\n",
    "\n",
    "# print(x_test['Gender'].unique())\n",
    "# print(x_test['Ever_Married'].unique())\n",
    "# print(x_test['Graduated'].unique())\n",
    "# print(x_test['Profession'].unique())\n",
    "# print(x_test['Spending_Score'].unique())\n",
    "\n",
    "x_train['Gender'] = x_train['Gender'].replace(['Male','Female'],[0,1])\n",
    "x_train['Ever_Married'] = x_train['Ever_Married'].replace(['No','Yes'],[0,1])\n",
    "x_train['Graduated'] = x_train['Graduated'].replace(['No','Yes'],[0,1])\n",
    "x_train['Profession'] = x_train['Profession'].map({'Healthcare':0, 'Engineer':1, \n",
    "                                                   'Lawyer':2, 'Artist':3, \n",
    "                                                   'Doctor':4, 'Homemaker':5,\n",
    "                                                   'Entertainment':6, 'Marketing':8, 'Executive':9})\n",
    "x_train['Spending_Score'] = x_train['Spending_Score'].replace(['Low','High','Average'],[0,1,2])\n",
    "\n",
    "x_test['Gender'] = x_test['Gender'].replace(['Male','Female'],[0,1])\n",
    "x_test['Ever_Married'] = x_test['Ever_Married'].replace(['No','Yes'],[0,1])\n",
    "x_test['Graduated'] = x_test['Graduated'].replace(['No','Yes'],[0,1])\n",
    "x_test['Profession'] = x_test['Profession'].map({'Healthcare':0, 'Engineer':1, \n",
    "                                                   'Lawyer':2, 'Artist':3, \n",
    "                                                   'Doctor':4, 'Homemaker':5,\n",
    "                                                   'Entertainment':6, 'Marketing':8, 'Executive':9})\n",
    "x_test['Spending_Score'] = x_test['Spending_Score'].replace(['Low','High','Average'],[0,1,2])\n",
    "# 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
    "# print(x_train.head(3))\n",
    "# print(x_test.head(3))\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "#                                                   y_train,\n",
    "#                                                   test_size=0.2,\n",
    "#                                                   stratify=y_train,\n",
    "#                                                   )\n",
    "# print(x_train.shape)\n",
    "# print(x_val.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)\n",
    "\n",
    "# 4. 모델링 및 성능평가\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(x_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(x_val)\n",
    "\n",
    "# from sklearn.metrics import f1_score, accuracy_score\n",
    "# f1 = f1_score(y_val, y_pred, average='macro')\n",
    "# acc = accuracy_score(y_val, y_pred)\n",
    "# print(f1)\n",
    "# print(acc)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "y_result = model.predict(x_train)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_train, y_result, average='macro')\n",
    "#print(f1)\n",
    "\n",
    "y_submit = model.predict(x_test)\n",
    "print(y_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f9e08-97ea-4413-989c-d280a3040a81",
   "metadata": {},
   "source": [
    "- 03 워싱턴 D.C의 Capital Bikeshare 프로그램에서 자전거 대여 수요를 예측하기 위한 프로젝트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0fc1916d-6fe4-4f0b-a841-19953ba0fd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.76036155726519\n"
     ]
    }
   ],
   "source": [
    "# 1. 라이브러리 및 데이터 확인\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/bike_train.csv')\n",
    "#print(df.head(3))\n",
    "#print(df.shape)\n",
    "#print(df.info()) # datetime dtype object\n",
    "# 3. 데이터 전처리 및 분리\n",
    "import datetime as dt\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "#print(df.head(3))\n",
    "drop_columns = ['datetime', 'casual', 'registered']\n",
    "df = df.drop(drop_columns, axis=1)\n",
    "#print(df.head(3))\n",
    "#print(df.isnull().sum())\n",
    "y = df['count']\n",
    "#print(y.shape)\n",
    "x = df.drop(['count'], axis=1)\n",
    "#print(x.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,\n",
    "                                                  y,\n",
    "                                                  test_size=0.3,\n",
    "                                                  random_state=0)\n",
    "# print(x_train.shape)\n",
    "# print(x_val.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)\n",
    "# 4. 모델링 및 성능평가\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_val)\n",
    "#print(y_pred)\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#print(mean_absolute_error(y_val, y_pred))\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "#print(rmse)\n",
    "#print(mean_squared_error(y_val, y_pred, squared=True))\n",
    "result_df = pd.DataFrame(y_val.values, columns=['real_count'])\n",
    "import numpy as np\n",
    "result_df['predict_count'] = np.round(y_pred)\n",
    "result_df['diff'] = np.abs(result_df['real_count']-result_df['predict_count'])\n",
    "#print(result_df.sort_values('diff', ascending=False).head(10))\n",
    "after_df = pd.get_dummies(df, columns=['year','month','day','hour','holiday','workingday','season','weather'], dtype='uint8')\n",
    "#print(after_df)\n",
    "y = after_df['count']\n",
    "x = after_df.drop(['count'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "x_train2, x_val2, y_train2, y_val2 = train_test_split(x,\n",
    "                                                      y,\n",
    "                                                      test_size=0.3,\n",
    "                                                      random_state=0)\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(x_train2, y_train2)\n",
    "y_pred2 = reg2.predict(x_val2)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# print(mean_absolute_error(y_val2, y_pred2))\n",
    "# print(mean_squared_error(y_val2, y_pred2, squared=False))\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=500)\n",
    "rf_reg.fit(x_train2, y_train2)\n",
    "y_pred2 = rf_reg.predict(x_val2)\n",
    "#print(mean_absolute_error(y_val2, y_pred2))\n",
    "print(mean_squared_error(y_val2, y_pred2, squared=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
